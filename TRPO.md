

### 1、Introduction

TRPO 是一种基于策略梯度理论的实际算法，确保每次更新都带来单调提升（策略性能不会下降）。

在理论基础上，论文做了一系列近似，以发展出可扩展、稳定的 TRPO 算法，能够优化高维非线性策略（例如神经网络）。

实验表明：TRPO 可在多个任务中实现稳健表现，如模拟机器人运动（游泳、跳跃、行走）以及使用图像玩 Atari 游戏。

TRPO的优势：

1. 保证策略性能单调提升，避免回退；
2. 对超参数的调整要求较低，使用起来更加稳定；
3. 能处理高维状态与策略参数，适用于复杂策略搜索。

### 2、Preliminaries

![image-20250712205925385](img/image-20250712205925385.png)