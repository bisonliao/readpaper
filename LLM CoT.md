**思维链提示（Chain-of-Thought Prompting）**

### 1）什么问题

虽然大型语言模型（LLMs）在许多自然语言处理任务中表现出色，但**仅仅通过扩大模型规模，并不能有效解决需要复杂推理的任务**，如算术推理（Arithmetic Reasoning）、常识推理（Commonsense Reasoning）和符号推理（Symbolic Reasoning）。

传统的**标准提示方法（Standard Prompting）**（即仅通过“输入-输出”示例进行少样本学习）在这些任务上表现较差，且往往不会随着模型规模的增加而显著改善。

### 2）如何解决

作者提出了一种极其简单且通用的方法：**思维链提示（Chain-of-Thought Prompting, CoT）**。

• **核心理念**：在向模型提供少样本示例（Exemplars）时，不只是给出最终答案，而是**增加一段中间自然语言推理步骤**（即“思维链”），引导模型得出最终输出。

• **方法特点**：

  ◦ **无需微调**：这是一种纯提示的方法，不需要更新模型参数或大型训练数据集。

  ◦ **通用性强**：原则上可以应用于任何人类可以通过语言解决的任务。

  ◦ **可解释性**：思维链提供了一个窗口，可以观察模型的推理路径，方便调试模型出错的地方。

论文明确指出，思维链推理是通过一种简单的**“纯提示方法”（prompting only approach）**实现的。具体操作是在 Few-shot（少样本）的提示词中，将传统的“输入-输出”对替换为“**输入-思维链-输出**”的三元组示例。模型通过模仿示例中的推理步骤，自然而然地学会了在输出答案前先生成中间推理过程,。

### 3）解决的效果如何

通过对三类推理任务（算术、常识、符号）的实验，研究发现：

• **性能显著提升**：在多个基准测试中，CoT 提示显著优于标准提示。例如，在 GSM8K 数学题基准测试中，配有 8 个 CoT 示例的 PaLM 540B 模型达到了 **SOTA（当时最尖端）** 的准确率，甚至超越了经过专门微调的 GPT-3。

• **规模触发的“涌现”能力**：CoT 提示的效果与模型规模密切相关。实验表明，思维链推理是一种**涌现能力（Emergent Ability）**，只有当模型规模达到约 **100B（千亿）级参数**时，性能才会有显著飞跃；在小规模模型上，CoT 往往会产生不合逻辑的推理，效果反而不如标准提示。

• **更好的泛化性**：在符号推理任务中，CoT 提示能够帮助模型实现**长度泛化**，即模型能够处理比示例中步骤更长的推理任务。

• **稳健性**：CoT 的效果对于不同的标注者编写的推理链，以及不同的示例选择都表现出了较强的**鲁棒性**（Robustness）。

**总结**：思维链提示通过简单的输出转换，极大地释放了大型语言模型的推理潜力，打破了标准提示方法在复杂逻辑任务上的局限性。该论文的核心贡献在于证明了：**复杂推理能力是大型语言模型规模化后的“涌现属性”**，我们**只需要改变 Prompt 的格式**（加入中间步骤示例），就能解锁这种能力，而无需进行昂贵的模型再训练或复杂的外部检索系统:

### 4) 核心贡献总结

1. **方法简单有效**：仅通过few-shot prompting中的示例设计，无需微调即可激发LLMs推理能力
2. **揭示涌现特性**：思维链推理是大型语言模型（≥100B参数）的涌现能力
3. **通用性强**：适用于算术、常识、符号等多种推理任务
4. **提升可解释性**：生成的思维链提供模型推理过程的"可解释窗口"
5. **突破性能瓶颈**：在多个基准测试上达到或超越专门微调模型的SOTA结果