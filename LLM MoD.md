### 1. 论文解决的问题

传统Transformer模型在前向传播中对序列中**所有token均匀分配计算资源**（FLOPs），但实际语言建模任务中，不同token位置对预测难度差异显著——某些位置（如常见词）可能无需复杂计算即可准确预测，而某些位置（如歧义词）则需要更多处理。这种"一刀切"的计算分配方式导致**计算资源浪费**。

现有条件计算（conditional computation）方法虽能动态分配计算，但多数引入**动态计算图**（如token数量不确定），与现代硬件（GPU/TPU）偏好**静态计算图+固定张量尺寸**的特性不兼容，难以获得实际加速。

论文核心目标：**在保持静态计算图（硬件友好）的前提下，实现token级别动态计算分配，减少总FLOPs和推理延迟，同时不牺牲模型性能**。

---

### 2. 解决方案：Mixture-of-Depths (MoD)

#### 核心思想
- 与MoE（Mixture-of-Experts）不同：MoE在多个expert间路由但**总计算量不变**；MoD在"完整计算"（self-attention + MLP）和"跳过计算"（残差连接直通）之间路由，**主动减少总FLOPs**。
- 与Early-Exit不同：MoD允许token**跳过中间层但后续仍可被处理**（例如跳过第5层但参与第6层的attention），而Early-Exit一旦退出则不再参与后续层。

#### 具体实现
1. **静态计算预算**  
   - 用户预定义capacity `k`（如序列长度的12.5%），限制每个block中参与self-attention和MLP的token数量。
   - 由于`k`固定，计算图静态、张量尺寸已知，硬件可高效调度。

2. **Expert-Choice路由机制**  
   - 每个block前设router，为每个token生成标量权重 `r_i = w^T x_i`。
   - 选择权重最高的`k`个tokens参与完整计算（self-attention + MLP），其余tokens通过残差连接直通（节省FLOPs）。
   - 优势：①天然负载均衡（恰好`k`个tokens被处理）；②无需辅助平衡损失；③相对权重可表达token重要性。

3. **因果性问题处理（推理阶段）**  
   - 训练时：使用non-causal的top-k（需整个序列的路由权重）。
   - 推理时：引入轻量辅助预测器（或辅助BCE损失），仅基于当前及历史token预测是否参与计算，实现causal自回归采样（准确率>97%）。

4. **关键设计选择**  
   - **隔层路由**（interleaved routing）：仅每隔一个block启用MoD，其余层保持全attention，避免性能下降。
   - **激进capacity缩减**：实验发现12.5% capacity（87.5% tokens跳过）效果最佳，模型对大幅缩减鲁棒。

---

### 3. 实验效果

#### 主要结果
- **IsoFLOP训练**（相同总训练FLOPs）：
  - 最优MoD模型比baseline **loss更低**（性能提升约1.5%），且参数量更大。
  - 存在"甜点"配置：如220M参数MoD（12.5% capacity + 隔层路由）**性能略优于**同参数baseline，但**每步FLOPs减少66%**，训练/推理速度提升50%–66%，且总训练时间（wall-clock）相当。

- **推理加速**：
  - 自回归采样时，用预测器替代top-k几乎无性能损失（<0.3% degradation）。
  - FLOPs减少直接转化为**推理延迟降低**（50%+加速），对长序列生成尤其有益。

- **消融实验**：
  - 随机路由（stochastic routing）性能大幅下降 → **学习到的智能路由至关重要**。
  - 隔层路由优于每层路由；12.5% capacity优于更高capacity（如50%）。
  - 增加模型**深度**比增加宽度更有效。

#### 附加优势
- **内存节省**：大模型训练时减少设备需求；推理时显著降低KV cache大小（因部分tokens跳过attention）。
- **与MoE兼容**：MoD+MoE（MoDE）性能提升可叠加，且优于单纯降低MoE expert capacity。
- **路由模式分析**：高频参与计算的tokens与高预测熵位置相关，表明模型学会将计算资源分配给"困难"位置。

#### 核心结论
MoD证明：**vanilla Transformer存在显著计算冗余**。通过学习动态跳过非必要计算，可在相同训练成本下获得更优性能，或在保持性能的同时大幅加速推理——为高效LLM设计提供新范式。



## 4、疑问

### 为什么在推理阶段和训练阶段使用不同的route机制

推理阶段与训练阶段使用不同 routing 机制，**根本原因在于 top-k 操作的 non-causal（非因果）特性与自回归生成的 causal（因果）要求之间的冲突**。具体分析如下：

---

#### 1. 训练阶段：non-causal top-k 路由

- **机制**：每个 token 经 router 生成标量权重 $r_i$，然后在整个序列范围内选取权重最高的 $k$ 个 tokens 参与完整计算（self-attention + MLP）。
- **问题**：该操作是 **non-causal** 的——判断第 $t$ 个 token 是否被选中，需要知道 *整个序列*（包括 $t+1, t+2, \dots$ 位置）所有 token 的路由权重，才能确定它是否落在 top-$k$ 中。
- **训练时可行**：因为训练时输入序列完整可见，可以一次性计算所有 token 的路由权重并执行全局 top-$k$ 选择。

---

#### 2. 推理阶段：必须满足 causal 约束

- **自回归生成要求**：生成第 $t$ 个 token 时，模型只能访问 $1 \dots t-1$ 位置的历史信息，**不能依赖未来 token**（$t, t+1, \dots$）。
- **top-k 不可用**：若沿用训练时的 top-$k$ 机制，需要提前知道整个待生成序列的路由权重才能做选择，这在自回归场景下**不可能实现**。

---

#### 3. 推理阶段的解决方案

论文提出两种 **causal-friendly** 的替代方案，均在训练阶段引入辅助机制，使推理时可仅基于当前及历史信息做路由决策：

| 方法                  | 机制                                                         | 优点                        | 缺点                                          |
| --------------------- | ------------------------------------------------------------ | --------------------------- | --------------------------------------------- |
| **辅助 BCE 损失**     | 在训练时添加二元交叉熵损失：以 top-$k$ 选择结果为 target（选中=1，跳过=0），迫使 router 输出 >0.5 表示“应参与计算” | 实现简单                    | 对主任务性能有轻微影响（~0.2–0.3% loss 增加） |
| **辅助预测器（MLP）** | 训练一个轻量 MLP 预测器（输入与 router 相同，带 stop-gradient），直接预测该 token 是否会在完整序列中被 top-$k$ 选中 | **无性能损失**，准确率 >97% | 需额外小网络                                  |

推理时只需用 router 输出（方法1）或预测器输出（方法2）与阈值 0.5 比较，即可决定是否参与计算，**完全满足 causal 约束**。

bison：我理解就是同步用监督学习训练一个判别器，只需要输入历史上的tokens和当前token，就可以输出0/1两个分类：是参与计算还是不参与计算。

---

#### 4. 为什么这种替代可行？

论文实验表明：
- 预测“是否应被 top-$k$ 选中”是一个**相对简单的任务**，辅助预测器很快达到 >97% 准确率。
- 这说明路由决策**主要依赖当前及历史上下文**，对未来的依赖较弱——模型学会将计算资源分配给“当前难以预测”的位置（如高熵预测），这类信号在局部上下文中已足够明显。

因此，虽然训练和推理的 routing 机制形式不同，但**语义一致**：都实现了“将有限计算资源动态分配给最需要的 token”，且推理阶段几乎无性能损失（<0.3%）。

### MoE在实际工程中广泛应用了吗？

答案是否定的。

#### 1 为什么MoD未被广泛采用？

| 原因                  | 说明                                                         |
| --------------------- | ------------------------------------------------------------ |
| **工程收益不明确**    | 理论FLOPs减少 ≠ 实际推理加速。现代GPU/TPU对标准Transformer高度优化，动态跳过计算可能因**内存访问不规则、kernel launch开销**抵消FLOPs优势 |
| **实现复杂度高**      | 需要训练-推理解耦的路由机制（如辅助预测器），增加训练复杂性和调试成本 |
| **与MoE相比竞争力弱** | • MoE：**保持计算量不变，大幅增加参数量** → 性能提升显著且工程友好（静态图） • MoD：**减少计算量，参数量不变** → 性能提升有限，且需处理动态稀疏性 |
| **缺乏规模化验证**    | 原论文仅在~220M–1B参数规模验证，未证明在10B+规模下的稳定性和收益 |
| **生态工具链缺失**    | Hugging Face Transformers、vLLM、TensorRT-LLM等推理框架**未原生支持MoD**，部署成本高 |

#### 2. 当前实际应用情况

- **学术研究**：少量后续工作探索类似思想（如Adaptive Token Skipping、Layer Dropping），但多为消融实验，未形成产品化方案
- **工业界**：据公开信息，**Google、Meta、Mistral AI、xAI等均未在已发布的开源模型中采用MoD**
- **闭源模型**：无明确证据表明GPT-4/5、Claude 3、Gemini 1.5等采用MoD（更可能采用MoE或稠密架构+模型压缩技术）